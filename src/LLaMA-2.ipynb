{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHATBOT-WITH-LLAMA-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T13:44:50.184920Z",
     "iopub.status.busy": "2025-03-26T13:44:50.184672Z",
     "iopub.status.idle": "2025-03-26T13:46:20.324032Z",
     "shell.execute_reply": "2025-03-26T13:46:20.323194Z",
     "shell.execute_reply.started": "2025-03-26T13:44:50.184900Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.6 which is incompatible.\n",
      "pathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.14 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting bitsandbytes==0.41.1\n",
      "  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.41.1\n"
     ]
    }
   ],
   "source": [
    "# Cập nhật pip trước khi cài đặt\n",
    "!pip install -U pip  -q\n",
    "\n",
    "# Cài đặt bitsandbytes phiên bản ổn định\n",
    "# !pip install bitsandbytes==0.39.0 --index-url https://jllllll.github.io/bitsandbytes-wheels/cu121/ -q\n",
    "\n",
    "# Cài đặt phiên bản PyTorch tương thích\n",
    "# !pip install -qqq torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  -q\n",
    "!pip install torch -q\n",
    "\n",
    "# Cài đặt transformers, peft và accelerate mới nhất\n",
    "!pip install -qqq -U git+https://github.com/huggingface/transformers.git  -q\n",
    "!pip install -qqq -U git+https://github.com/huggingface/peft.git  -q\n",
    "!pip install -qqq -U git+https://github.com/huggingface/accelerate.git  -q\n",
    "\n",
    "# Cài đặt các thư viện hỗ trợ\n",
    "!pip install -qqq datasets==2.12.0  -q\n",
    "!pip install -qqq loralib==0.1.1  -q\n",
    "!pip install -qqq einops==0.6.1  -q\n",
    "!pip install -qqq wandb  -q\n",
    "!pip install bitsandbytes==0.41.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T13:46:20.327857Z",
     "iopub.status.busy": "2025-03-26T13:46:20.327552Z",
     "iopub.status.idle": "2025-03-26T13:46:26.612091Z",
     "shell.execute_reply": "2025-03-26T13:46:26.611034Z",
     "shell.execute_reply.started": "2025-03-26T13:46:20.327822Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T13:46:26.613445Z",
     "iopub.status.busy": "2025-03-26T13:46:26.613179Z",
     "iopub.status.idle": "2025-03-26T13:46:57.843196Z",
     "shell.execute_reply": "2025-03-26T13:46:57.842517Z",
     "shell.execute_reply.started": "2025-03-26T13:46:26.613422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import bitsandbytes as bnb\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "import os\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, AutoPeftModelForCausalLM\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed, Trainer, TrainingArguments, BitsAndBytesConfig, \\\n",
    "    DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T10:59:40.251793Z",
     "iopub.status.busy": "2025-03-26T10:59:40.251163Z",
     "iopub.status.idle": "2025-03-26T10:59:40.255535Z",
     "shell.execute_reply": "2025-03-26T10:59:40.254715Z",
     "shell.execute_reply.started": "2025-03-26T10:59:40.251766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:41:56.685431Z",
     "iopub.status.busy": "2025-03-25T13:41:56.685122Z",
     "iopub.status.idle": "2025-03-25T13:41:56.830080Z",
     "shell.execute_reply": "2025-03-25T13:41:56.829184Z",
     "shell.execute_reply.started": "2025-03-25T13:41:56.685400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:41:56.830996Z",
     "iopub.status.busy": "2025-03-25T13:41:56.830718Z",
     "iopub.status.idle": "2025-03-25T13:41:56.844307Z",
     "shell.execute_reply": "2025-03-25T13:41:56.843506Z",
     "shell.execute_reply.started": "2025-03-25T13:41:56.830974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Importing Llama 2 Chat HF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:41:56.845378Z",
     "iopub.status.busy": "2025-03-25T13:41:56.845100Z",
     "iopub.status.idle": "2025-03-25T13:41:56.858171Z",
     "shell.execute_reply": "2025-03-25T13:41:56.857356Z",
     "shell.execute_reply.started": "2025-03-25T13:41:56.845339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"vilm/vinallama-2.7b-chat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performing Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:41:56.860848Z",
     "iopub.status.busy": "2025-03-25T13:41:56.860589Z",
     "iopub.status.idle": "2025-03-25T13:41:56.871693Z",
     "shell.execute_reply": "2025-03-25T13:41:56.870985Z",
     "shell.execute_reply.started": "2025-03-25T13:41:56.860827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def load_model(model_name, bnb_config):\n",
    "#     n_gpus = torch.cuda.device_count()\n",
    "#     max_memory = f'{40960}MB'\n",
    "\n",
    "#     model = AutoModelForCausalLM.from_pretrained(\n",
    "#         model_name,\n",
    "#         quantization_config=bnb_config,\n",
    "#         device_map=\"auto\", # dispatch efficiently the model on the available ressources\n",
    "#         max_memory = {i: max_memory for i in range(n_gpus)},\n",
    "#     )\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=False)\n",
    "\n",
    "#     # Needed for LLaMA tokenizer\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "#     return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:41:56.873418Z",
     "iopub.status.busy": "2025-03-25T13:41:56.873156Z",
     "iopub.status.idle": "2025-03-25T13:42:11.026597Z",
     "shell.execute_reply": "2025-03-25T13:42:11.025778Z",
     "shell.execute_reply.started": "2025-03-25T13:41:56.873378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Detailed Content</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer_Start</th>\n",
       "      <th>Answer_End</th>\n",
       "      <th>Reference Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rào_cản tự_nhiên chống lại nhiễm_trùng về da</td>\n",
       "      <td>da thường chặn các vi_sinh_vật xâm_nhập trừ kh...</td>\n",
       "      <td>da thường chặn các vi_sinh_vật xâm_nhập trừ kh...</td>\n",
       "      <td>da, vi_sinh_vật, động_vật, ống, iv, chặn, xâm_...</td>\n",
       "      <td>Liệu da có vai trò gì trong rào_cản tự_nhiên c...</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>https://www.msdmanuals.com/vi-vn/professional/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rào_cản tự_nhiên chống lại nhiễm_trùng về da</td>\n",
       "      <td>da thường chặn các vi_sinh_vật xâm_nhập trừ kh...</td>\n",
       "      <td>da thường chặn các vi_sinh_vật xâm_nhập trừ kh...</td>\n",
       "      <td>da, vi_sinh_vật, động_vật, ống, iv, chặn, xâm_...</td>\n",
       "      <td>Tại sao vi_sinh_vật lại xâm_nhập trong bối cản...</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>https://www.msdmanuals.com/vi-vn/professional/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rào_cản tự_nhiên chống lại nhiễm_trùng về da</td>\n",
       "      <td>da thường chặn các vi_sinh_vật xâm_nhập trừ kh...</td>\n",
       "      <td>da thường chặn các vi_sinh_vật xâm_nhập trừ kh...</td>\n",
       "      <td>da, vi_sinh_vật, động_vật, ống, iv, chặn, xâm_...</td>\n",
       "      <td>trừ động_vật có ảnh hưởng như thế nào đến rào_...</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>https://www.msdmanuals.com/vi-vn/professional/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rào_cản tự_nhiên chống lại nhiễm_trùng về da</td>\n",
       "      <td>da thường chặn các vi_sinh_vật xâm_nhập trừ kh...</td>\n",
       "      <td>các ngoại_lệ bao_gồm virus papilloma_người có_...</td>\n",
       "      <td>ngoại_lệ, virus, papilloma_người, da, mụn, cóc...</td>\n",
       "      <td>Sự kết hợp giữa ngoại_lệ và ngoại_lệ có thể ba...</td>\n",
       "      <td>140</td>\n",
       "      <td>479</td>\n",
       "      <td>https://www.msdmanuals.com/vi-vn/professional/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rào_cản tự_nhiên chống lại nhiễm_trùng về da</td>\n",
       "      <td>da thường chặn các vi_sinh_vật xâm_nhập trừ kh...</td>\n",
       "      <td>các ngoại_lệ bao_gồm virus papilloma_người có_...</td>\n",
       "      <td>ngoại_lệ, virus, papilloma_người, da, mụn, cóc...</td>\n",
       "      <td>Tại sao virus lại cần xâm_nhập trong rào_cản t...</td>\n",
       "      <td>140</td>\n",
       "      <td>479</td>\n",
       "      <td>https://www.msdmanuals.com/vi-vn/professional/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "0  rào_cản tự_nhiên chống lại nhiễm_trùng về da   \n",
       "1  rào_cản tự_nhiên chống lại nhiễm_trùng về da   \n",
       "2  rào_cản tự_nhiên chống lại nhiễm_trùng về da   \n",
       "3  rào_cản tự_nhiên chống lại nhiễm_trùng về da   \n",
       "4  rào_cản tự_nhiên chống lại nhiễm_trùng về da   \n",
       "\n",
       "                                    Detailed Content  \\\n",
       "0  da thường chặn các vi_sinh_vật xâm_nhập trừ kh...   \n",
       "1  da thường chặn các vi_sinh_vật xâm_nhập trừ kh...   \n",
       "2  da thường chặn các vi_sinh_vật xâm_nhập trừ kh...   \n",
       "3  da thường chặn các vi_sinh_vật xâm_nhập trừ kh...   \n",
       "4  da thường chặn các vi_sinh_vật xâm_nhập trừ kh...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  da thường chặn các vi_sinh_vật xâm_nhập trừ kh...   \n",
       "1  da thường chặn các vi_sinh_vật xâm_nhập trừ kh...   \n",
       "2  da thường chặn các vi_sinh_vật xâm_nhập trừ kh...   \n",
       "3  các ngoại_lệ bao_gồm virus papilloma_người có_...   \n",
       "4  các ngoại_lệ bao_gồm virus papilloma_người có_...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  da, vi_sinh_vật, động_vật, ống, iv, chặn, xâm_...   \n",
       "1  da, vi_sinh_vật, động_vật, ống, iv, chặn, xâm_...   \n",
       "2  da, vi_sinh_vật, động_vật, ống, iv, chặn, xâm_...   \n",
       "3  ngoại_lệ, virus, papilloma_người, da, mụn, cóc...   \n",
       "4  ngoại_lệ, virus, papilloma_người, da, mụn, cóc...   \n",
       "\n",
       "                                            Question  Answer_Start  \\\n",
       "0  Liệu da có vai trò gì trong rào_cản tự_nhiên c...             0   \n",
       "1  Tại sao vi_sinh_vật lại xâm_nhập trong bối cản...             0   \n",
       "2  trừ động_vật có ảnh hưởng như thế nào đến rào_...             0   \n",
       "3  Sự kết hợp giữa ngoại_lệ và ngoại_lệ có thể ba...           140   \n",
       "4  Tại sao virus lại cần xâm_nhập trong rào_cản t...           140   \n",
       "\n",
       "   Answer_End                                     Reference Link  \n",
       "0         139  https://www.msdmanuals.com/vi-vn/professional/...  \n",
       "1         139  https://www.msdmanuals.com/vi-vn/professional/...  \n",
       "2         139  https://www.msdmanuals.com/vi-vn/professional/...  \n",
       "3         479  https://www.msdmanuals.com/vi-vn/professional/...  \n",
       "4         479  https://www.msdmanuals.com/vi-vn/professional/...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/dataset-medical-full/processed_medical_full.csv\")\n",
    "df = df.head(15000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:42:11.027672Z",
     "iopub.status.busy": "2025-03-25T13:42:11.027435Z",
     "iopub.status.idle": "2025-03-25T13:42:11.033039Z",
     "shell.execute_reply": "2025-03-25T13:42:11.032231Z",
     "shell.execute_reply.started": "2025-03-25T13:42:11.027652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_prompt_formats(sample):\n",
    "    \"\"\"\n",
    "    Định dạng dữ liệu từ mẫu ('question', 'answer', 'context') theo định dạng ChatML\n",
    "    :param sample: Từ điển mẫu chứa dữ liệu (bao gồm 'context' nếu có)\n",
    "    \"\"\"\n",
    "\n",
    "    SYSTEM_PROMPT = \"<|im_start|>system\\nBạn là một trợ lí AI hữu ích. Hãy trả lời người dùng một cách chính xác.\\n<|im_end>\"\n",
    "    CONTEXT_PROMPT = \"<|im_start|>context\\n{context}\\n<|im_end>\"  # Phần context mới\n",
    "    USER_PROMPT = \"<|im_start|>user\\n{question}\\n<|im_end>\"\n",
    "    ASSISTANT_PROMPT = \"<|im_start|>assistant\\n{answer}\\n<|im_end>\"\n",
    "    \n",
    "    # Định dạng từng phần\n",
    "    system_part = SYSTEM_PROMPT\n",
    "    context_part = CONTEXT_PROMPT.format(context=sample['Detailed Content']) if 'Detailed Content' in sample else \"\"\n",
    "    user_part = USER_PROMPT.format(question=sample['Question']) if 'Question' in sample else \"\"\n",
    "    assistant_part = ASSISTANT_PROMPT.format(answer=sample['Answer']) if 'Answer' in sample else \"\"\n",
    "    \n",
    "    # Nối các phần bằng hai ký tự xuống dòng, bỏ qua None\n",
    "    parts = [part for part in [system_part, context_part, user_part, assistant_part] if part]\n",
    "    formatted_prompt = \"\\n\\n\".join(parts)\n",
    "    \n",
    "    # Thêm trường 'text' vào sample\n",
    "    sample[\"text\"] = formatted_prompt\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:42:11.034243Z",
     "iopub.status.busy": "2025-03-25T13:42:11.033952Z",
     "iopub.status.idle": "2025-03-25T13:42:11.051351Z",
     "shell.execute_reply": "2025-03-25T13:42:11.050531Z",
     "shell.execute_reply.started": "2025-03-25T13:42:11.034216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# SOURCE https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\n",
    "def get_max_length(model):\n",
    "    conf = model.config\n",
    "    max_length = None\n",
    "    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n",
    "        max_length = getattr(model.config, length_setting, None)\n",
    "        if max_length:\n",
    "            print(f\"Found max lenth: {max_length}\")\n",
    "            break\n",
    "    if not max_length:\n",
    "        max_length = 1024\n",
    "        print(f\"Using default max length: {max_length}\")\n",
    "    return max_length\n",
    "\n",
    "\n",
    "# def preprocess_batch(batch, tokenizer, max_length):\n",
    "#     \"\"\"\n",
    "#     Tokenizing a batch\n",
    "#     \"\"\"\n",
    "#     return tokenizer(\n",
    "#         batch[\"text\"],\n",
    "#         max_length=max_length,\n",
    "#         truncation=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:42:11.052265Z",
     "iopub.status.busy": "2025-03-25T13:42:11.051989Z",
     "iopub.status.idle": "2025-03-25T13:42:11.071464Z",
     "shell.execute_reply": "2025-03-25T13:42:11.070731Z",
     "shell.execute_reply.started": "2025-03-25T13:42:11.052246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:42:11.072513Z",
     "iopub.status.busy": "2025-03-25T13:42:11.072257Z",
     "iopub.status.idle": "2025-03-25T13:42:11.086873Z",
     "shell.execute_reply": "2025-03-25T13:42:11.086311Z",
     "shell.execute_reply.started": "2025-03-25T13:42:11.072483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(tokenizer: AutoTokenizer, max_length: int, seed: int, dataset: Dataset) -> Dataset:\n",
    "    \"\"\"\n",
    "    Format & tokenize dataset to prepare it for training.\n",
    "    \n",
    "    :param tokenizer: AutoTokenizer instance for tokenizing text\n",
    "    :param max_length: Maximum number of tokens allowed in tokenized output\n",
    "    :param seed: Random seed for shuffling dataset\n",
    "    :param dataset: Hugging Face Dataset object to preprocess\n",
    "    :return: Preprocessed and tokenized Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Kiểm tra kiểu dữ liệu đầu vào\n",
    "    if not isinstance(dataset, Dataset):\n",
    "        raise ValueError(\"dataset must be a Hugging Face Dataset object\")\n",
    "    # if not isinstance(tokenizer, AutoTokenizer):\n",
    "    #     raise ValueError(\"tokenizer must be an AutoTokenizer instance\")\n",
    "\n",
    "    # Thêm prompt vào mỗi mẫu bằng cách áp dụng create_prompt_formats\n",
    "    print(\"Preprocessing dataset...\")\n",
    "    dataset = dataset.map(create_prompt_formats)  # Không cần batched=True vì hàm xử lý từng mẫu\n",
    "\n",
    "    # Hàm tiền xử lý batch để tokenize\n",
    "    def preprocess_batch(batch, max_length: int, tokenizer: AutoTokenizer):\n",
    "        \"\"\"\n",
    "        Tokenize a batch of text data.\n",
    "        \n",
    "        :param batch: Batch of data with 'text' field\n",
    "        :param max_length: Maximum token length\n",
    "        :param tokenizer: Tokenizer instance\n",
    "        :return: Tokenized batch\n",
    "        \"\"\"\n",
    "        # Tokenize trường 'text' từ create_prompt_formats\n",
    "        tokenized = tokenizer(\n",
    "            batch[\"text\"],\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "            padding=False,  # Không padding ở đây, để DataCollator xử lý sau\n",
    "            return_tensors=\"np\"  # Trả về numpy để tương thích với Dataset\n",
    "        )\n",
    "        return tokenized\n",
    "\n",
    "    # Áp dụng tokenization và xóa các cột cũ\n",
    "    _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n",
    "    dataset = dataset.map(\n",
    "        _preprocessing_function,\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names,  # Xóa tất cả cột cũ (question, answer, context, v.v.)\n",
    "    )\n",
    "\n",
    "    # Lọc các mẫu vượt quá max_length\n",
    "    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
    "\n",
    "    # Xáo trộn dataset\n",
    "    dataset = dataset.shuffle(seed=seed)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:42:11.088022Z",
     "iopub.status.busy": "2025-03-25T13:42:11.087718Z",
     "iopub.status.idle": "2025-03-25T13:42:11.104533Z",
     "shell.execute_reply": "2025-03-25T13:42:11.103839Z",
     "shell.execute_reply.started": "2025-03-25T13:42:11.087994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_bnb_config():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "    return bnb_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:42:11.105481Z",
     "iopub.status.busy": "2025-03-25T13:42:11.105266Z",
     "iopub.status.idle": "2025-03-25T13:42:11.118067Z",
     "shell.execute_reply": "2025-03-25T13:42:11.117239Z",
     "shell.execute_reply.started": "2025-03-25T13:42:11.105456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_peft_config(modules):\n",
    "    \"\"\"\n",
    "    Create Parameter-Efficient Fine-Tuning config for your model\n",
    "    :param modules: Names of the modules to apply Lora to\n",
    "    \"\"\"\n",
    "    config = LoraConfig(\n",
    "        r=16,  # dimension of the updated matrices\n",
    "        lora_alpha=64,  # parameter for scaling\n",
    "        target_modules=modules,\n",
    "        lora_dropout=0.1,  # dropout probability for layers\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:42:11.118925Z",
     "iopub.status.busy": "2025-03-25T13:42:11.118725Z",
     "iopub.status.idle": "2025-03-25T13:42:11.131573Z",
     "shell.execute_reply": "2025-03-25T13:42:11.130971Z",
     "shell.execute_reply.started": "2025-03-25T13:42:11.118889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16-bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:42:11.132667Z",
     "iopub.status.busy": "2025-03-25T13:42:11.132426Z",
     "iopub.status.idle": "2025-03-25T13:42:11.151101Z",
     "shell.execute_reply": "2025-03-25T13:42:11.150228Z",
     "shell.execute_reply.started": "2025-03-25T13:42:11.132636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model, use_4bit=False):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        num_params = param.numel()\n",
    "        # if using DS Zero 3 and the weights are initialized empty\n",
    "        if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
    "            num_params = param.ds_numel\n",
    "\n",
    "        all_param += num_params\n",
    "        if param.requires_grad:\n",
    "            trainable_params += num_params\n",
    "    if use_4bit:\n",
    "        trainable_params /= 2\n",
    "    print(\n",
    "        f\"all params: {all_param:,d} || trainable params: {trainable_params:,d} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:42:11.152055Z",
     "iopub.status.busy": "2025-03-25T13:42:11.151814Z",
     "iopub.status.idle": "2025-03-25T13:42:45.069742Z",
     "shell.execute_reply": "2025-03-25T13:42:45.068690Z",
     "shell.execute_reply.started": "2025-03-25T13:42:11.152036Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570de3c25cb845dcb93805e252222621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/682 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf363324c8784415ba2335eb56c5fa25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3cb3b8804244718ca08d71006e80cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd642db1b8644ed5acfa6ed2f34e9179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fb9d3bb4a94c34b85b89bb48a67499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45875d66ec68411c86786e40c9f351b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9391408ea04c8eb4a28fe461dbbc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/558 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = create_bnb_config()\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.gradient_checkpointing_enable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:42:45.071979Z",
     "iopub.status.busy": "2025-03-25T13:42:45.071508Z",
     "iopub.status.idle": "2025-03-25T13:42:45.323213Z",
     "shell.execute_reply": "2025-03-25T13:42:45.322120Z",
     "shell.execute_reply.started": "2025-03-25T13:42:45.071886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:42:45.324483Z",
     "iopub.status.busy": "2025-03-25T13:42:45.324245Z",
     "iopub.status.idle": "2025-03-25T13:43:16.820664Z",
     "shell.execute_reply": "2025-03-25T13:43:16.819592Z",
     "shell.execute_reply.started": "2025-03-25T13:42:45.324461Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found max lenth: 4096\n",
      "Preprocessing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = get_max_length(model)\n",
    "\n",
    "dataset = preprocess_dataset(tokenizer, 1500, 42, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:43:16.822213Z",
     "iopub.status.busy": "2025-03-25T13:43:16.821867Z",
     "iopub.status.idle": "2025-03-25T13:43:16.826238Z",
     "shell.execute_reply": "2025-03-25T13:43:16.825191Z",
     "shell.execute_reply.started": "2025-03-25T13:43:16.822187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dataset[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:43:16.827420Z",
     "iopub.status.busy": "2025-03-25T13:43:16.827147Z",
     "iopub.status.idle": "2025-03-25T13:43:16.842886Z",
     "shell.execute_reply": "2025-03-25T13:43:16.841976Z",
     "shell.execute_reply.started": "2025-03-25T13:43:16.827392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as nnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:43:16.847185Z",
     "iopub.status.busy": "2025-03-25T13:43:16.846826Z",
     "iopub.status.idle": "2025-03-25T13:43:16.858342Z",
     "shell.execute_reply": "2025-03-25T13:43:16.857396Z",
     "shell.execute_reply.started": "2025-03-25T13:43:16.847163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dataset[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T13:43:16.860056Z",
     "iopub.status.busy": "2025-03-25T13:43:16.859768Z",
     "iopub.status.idle": "2025-03-25T22:54:12.589715Z",
     "shell.execute_reply": "2025-03-25T22:54:12.588975Z",
     "shell.execute_reply.started": "2025-03-25T13:43:16.860002Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Model is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n",
      "Using auto half precision backend\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all params: 1,531,064,832 || trainable params: 25,034,752 || trainable%: 1.6351203082169679\n",
      "Checking dataset sample:\n",
      "torch.float32: 262287872 (17.13%)\n",
      "torch.uint8: 1268776960 (82.87%)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 13,335\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 416\n",
      "  Number of trainable parameters = 25,034,752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking devices at first step:\n",
      "Input input_ids is on device: cuda:0\n",
      "Input attention_mask is on device: cuda:0\n",
      "Input labels is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='416' max='416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [416/416 9:09:58, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12.667600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12.831300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.226600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.927600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>10.801100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9.764400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9.225200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8.954300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>8.561700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>8.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>7.453300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>8.187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>7.385400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>7.543900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>7.203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>7.764800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>7.082300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>7.288800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>7.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.773900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>6.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>6.832400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>6.556700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>6.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>6.781900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>6.914400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>6.565700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>6.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>6.389400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.179300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>5.878900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>5.957500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>6.319300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>5.979500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>5.816800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>5.873700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>5.296300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>5.943900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>6.176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6.412700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>5.803300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>5.640100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>5.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>5.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>5.487100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>5.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>5.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>5.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>5.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>5.627300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>5.418700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>5.918600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>4.931700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>4.805900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>5.195900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>5.327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>4.970200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>4.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.740700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>4.739100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>4.867300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>4.815300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>5.402800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>4.508900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>4.446400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>4.772400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>4.852400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>4.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.183200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>4.734700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>4.101100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>4.949100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>4.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>4.288200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>4.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>3.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>3.739200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>4.261500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.633200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>3.917300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>3.557100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>3.735700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>3.687300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>3.078400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>3.854500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>3.893900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3.975100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>3.774700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.597000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>3.323800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>3.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>3.952400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>3.289900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>3.130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>3.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>2.918100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>2.996900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>3.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.821200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>2.768100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>3.450900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>3.287300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>2.803200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>2.928100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>3.186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>3.084800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>2.449300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>2.861200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.229200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>3.461700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>2.492500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>3.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>2.337200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>2.273300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>2.728900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>2.449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>3.068100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>2.659500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.043900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>2.649100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>2.926200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>2.429100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>2.129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.498500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>3.071700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>1.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>2.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>1.987300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.804700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>2.463300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>2.427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>1.965500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>2.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.796400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>2.199600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>1.829200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>2.311400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>2.269000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>2.157000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>2.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>1.641700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>1.900600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>2.282600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>2.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>1.834200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>1.916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>2.268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.175500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>2.208400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>1.804200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>2.188900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>1.932800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.486200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>1.594200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>2.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>2.207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>1.701500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>2.499600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>2.175400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>2.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>2.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>2.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>1.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.603900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>2.181100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>1.801300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>1.396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>1.529500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>1.790200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.181200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>1.243700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>1.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>1.190500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>1.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.164800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1.130800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1.592800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1.650500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.525500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.921900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>1.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>1.515800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>1.529500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.527000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>1.313600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>1.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.972300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>1.469500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.164100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>1.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>1.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1.330900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>0.941100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>1.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.921200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>1.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>1.218700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>1.195900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>1.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>1.367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.765900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.994800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.907100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>1.661300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>1.064200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.949400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.879300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>1.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>1.191500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>1.071800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.424100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>1.118600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.779200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>1.083600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>1.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>1.454500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.664800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.781600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.923700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.958300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.685800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>1.353900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.644700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>1.453100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.922200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>1.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.599700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.810600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.817700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>1.325800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.556800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.963800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.579200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.779200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>0.643200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.606400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.710400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.877800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.709100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>0.925700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>0.865700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>0.703700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0.877200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>0.834600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>0.401100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.938000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.886300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>0.784800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>0.703900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>0.590500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>0.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.736300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>0.635200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>0.796400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>0.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.881100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>0.598200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>0.464200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>0.959100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>0.426700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>0.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>0.513400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>0.740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>0.574700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.650400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>0.469200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.844200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>0.757300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>0.972400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>0.493000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>0.709400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0.871900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.498300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.751000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.504100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.505400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>0.318800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.646400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>0.526900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>0.498700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>0.298100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>0.607600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>0.765100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>0.528800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>0.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>0.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>0.286600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311</td>\n",
       "      <td>0.421900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>0.774500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313</td>\n",
       "      <td>0.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>0.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>0.552300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>0.416300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317</td>\n",
       "      <td>0.580200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>0.422500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>0.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>0.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>0.570800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>0.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>0.370400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.380600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>0.363900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>0.981100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>0.561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>0.308600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.345200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>0.625500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>0.449300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>0.418100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>0.484900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>0.672400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337</td>\n",
       "      <td>0.578000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339</td>\n",
       "      <td>0.683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.456800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>0.509500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>0.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>0.382700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>0.471500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>0.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>0.488400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>0.418900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>0.446400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>0.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.605800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351</td>\n",
       "      <td>0.387600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.602700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>0.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354</td>\n",
       "      <td>0.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>0.470900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>0.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>0.532400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358</td>\n",
       "      <td>0.946300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>0.489700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.245600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>0.302200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>0.368200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>0.273400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>0.484200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367</td>\n",
       "      <td>0.319500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368</td>\n",
       "      <td>0.318300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>0.393300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371</td>\n",
       "      <td>0.442300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>0.365900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>0.349400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>0.275500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.330300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>0.380800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377</td>\n",
       "      <td>0.306300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>0.319800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>0.493000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.713400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>0.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>0.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>0.369900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.341700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>0.332700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>0.245500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388</td>\n",
       "      <td>0.794200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>0.281900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.344600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>0.353700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>0.370300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>0.459100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>0.326100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>0.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>0.411500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>0.281900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>0.312400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>0.316500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.405200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>0.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402</td>\n",
       "      <td>0.379900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>0.294300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404</td>\n",
       "      <td>0.272300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>0.270100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407</td>\n",
       "      <td>0.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>0.258800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>409</td>\n",
       "      <td>0.458400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411</td>\n",
       "      <td>0.293100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>0.317100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>0.566800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>0.328600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>0.384400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.361000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to outputs/checkpoint-416\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vilm--vinallama-2.7b-chat/snapshots/b31d5f1306494b2bf10ecb0c6031077af3f5b39a/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 46304,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2560,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 6912,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 20,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 20,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.0.dev0\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 46306\n",
      "}\n",
      "\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "tokenizer config file saved in outputs/checkpoint-416/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-416/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =      0.9982\n",
      "  total_flos               = 244954841GF\n",
      "  train_loss               =      2.1696\n",
      "  train_runtime            =  9:10:53.80\n",
      "  train_samples_per_second =       0.403\n",
      "  train_steps_per_second   =       0.013\n",
      "Training metrics: {'train_runtime': 33053.801, 'train_samples_per_second': 0.403, 'train_steps_per_second': 0.013, 'total_flos': 2.630182587700101e+17, 'train_loss': 2.1696005278052044, 'epoch': 0.9982003599280144}\n",
      "Saving last checkpoint of the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vilm--vinallama-2.7b-chat/snapshots/b31d5f1306494b2bf10ecb0c6031077af3f5b39a/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 46304,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2560,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 6912,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 20,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 20,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.0.dev0\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 46306\n",
      "}\n",
      "\n",
      "tokenizer config file saved in /kaggle/working/model/finetune/tokenizer_config.json\n",
      "Special tokens file saved in /kaggle/working/model/finetune/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, device=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.device = device or torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.first_step = True\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # Chuyển tất cả inputs sang thiết bị của mô hình\n",
    "        inputs = {k: v.to(self.device) if torch.is_tensor(v) else v for k, v in inputs.items()}\n",
    "        \n",
    "        # Kiểm tra thiết bị ở bước đầu tiên\n",
    "        if self.first_step:\n",
    "            print(\"Checking devices at first step:\")\n",
    "            for k, v in inputs.items():\n",
    "                if torch.is_tensor(v):\n",
    "                    print(f\"Input {k} is on device: {v.device}\")\n",
    "            self.first_step = False\n",
    "        \n",
    "        # Tính toán outputs\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        # Kiểm tra thiết bị của outputs (nếu cần)\n",
    "        if self.first_step:\n",
    "            print(f\"Outputs device: {outputs.logits.device}\")\n",
    "        \n",
    "        # Lấy loss từ outputs (DataCollatorForLanguageModeling tự tính loss)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def train(model, tokenizer, dataset, output_dir, num_epochs=1):\n",
    "    # Ép chỉ dùng cuda:0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Kích hoạt gradient checkpointing\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "    # Chuẩn bị model cho k-bit training\n",
    "    from peft import prepare_model_for_kbit_training, get_peft_model\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    # Tìm các module LoRA\n",
    "    modules = find_all_linear_names(model)\n",
    "    peft_config = create_peft_config(modules)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    print_trainable_parameters(model)\n",
    "\n",
    "    # Kiểm tra dataset sample\n",
    "    print(\"Checking dataset sample:\")\n",
    "    sample = dataset[0]\n",
    "    for k, v in sample.items():\n",
    "        if torch.is_tensor(v):\n",
    "            print(f\"Dataset {k} is on device: {v.device}\")\n",
    "\n",
    "    # Cấu hình huấn luyện\n",
    "    training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=8,  # Giảm để tránh OOM\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=2,\n",
    "        num_train_epochs=num_epochs,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        log_level=\"info\",\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        report_to=\"none\",\n",
    "        disable_tqdm=False,\n",
    "    )\n",
    "    \n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset,\n",
    "        args=training_args,\n",
    "        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    model.config.use_cache = False\n",
    "    \n",
    "    # Kiểm tra kiểu dữ liệu trước khi huấn luyện\n",
    "    dtypes = {}\n",
    "    for _, p in model.named_parameters():\n",
    "        dtype = p.dtype\n",
    "        if dtype not in dtypes:\n",
    "            dtypes[dtype] = 0\n",
    "        dtypes[dtype] += p.numel()\n",
    "    total = sum(dtypes.values())\n",
    "    for k, v in dtypes.items():\n",
    "        print(f\"{k}: {v} ({v/total:.2%})\")\n",
    "    \n",
    "    # Huấn luyện\n",
    "    print(\"Training...\")\n",
    "    try:\n",
    "        train_result = trainer.train()\n",
    "        metrics = train_result.metrics\n",
    "        trainer.log_metrics(\"train\", metrics)\n",
    "        trainer.save_metrics(\"train\", metrics)\n",
    "        trainer.save_state()\n",
    "        print(\"Training metrics:\", metrics)\n",
    "    except Exception as e:\n",
    "        print(f\"Training failed with error: {e}\")\n",
    "    \n",
    "    # Lưu mô hình\n",
    "    print(\"Saving last checkpoint of the model...\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    trainer.model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    # Giải phóng bộ nhớ\n",
    "    # del model\n",
    "    # del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Gọi hàm\n",
    "output_dir = \"/kaggle/working/model/finetune\"\n",
    "train(model, tokenizer, dataset, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T22:54:12.591089Z",
     "iopub.status.busy": "2025-03-25T22:54:12.590762Z",
     "iopub.status.idle": "2025-03-25T22:54:12.594380Z",
     "shell.execute_reply": "2025-03-25T22:54:12.593719Z",
     "shell.execute_reply.started": "2025-03-25T22:54:12.591057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Import Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T13:46:57.845435Z",
     "iopub.status.busy": "2025-03-26T13:46:57.844800Z",
     "iopub.status.idle": "2025-03-26T13:48:25.699598Z",
     "shell.execute_reply": "2025-03-26T13:48:25.698368Z",
     "shell.execute_reply.started": "2025-03-26T13:46:57.845410Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31c257a1ede46cc8dad06c1ed07abe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/682 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987b5d94585b47b297f38082bac0ef08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723ae2ff87384085ad98c29a19441822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b961a7fe2f5418e901992fe43663478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adapter_path = \"/kaggle/working/model/finetune\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T22:54:12.595542Z",
     "iopub.status.busy": "2025-03-25T22:54:12.595253Z",
     "iopub.status.idle": "2025-03-25T22:54:12.621239Z",
     "shell.execute_reply": "2025-03-25T22:54:12.620577Z",
     "shell.execute_reply.started": "2025-03-25T22:54:12.595514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Path to your fine-tuned adapter\n",
    "# # adapter_path = \"/kaggle/input/llama-vi/pytorch/default/1\"\n",
    "# adapter_path = \"/kaggle/working/model/finetune\"\n",
    "\n",
    "# # Load the base pre-trained model (LLaMA-2 7B)\n",
    "# base_model_name = \"vilm/vinallama-2.7b-chat\"  # Adjust if you used a different variant\n",
    "# tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "# # Load the base model\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(base_model_name)\n",
    "\n",
    "# # Check the vocab size of the base tokenizer\n",
    "# print(\"Base tokenizer vocab size:\", tokenizer.vocab_size)  # Should be 46304\n",
    "\n",
    "# # Load the fine-tuned tokenizer (if modified during fine-tuning)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "# print(\"Fine-tuned tokenizer vocab size:\", tokenizer.vocab_size)  # Should be 46652\n",
    "\n",
    "# # Resize the model's embeddings to match the fine-tuned tokenizer's vocab size\n",
    "# base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# # Load the adapter weights\n",
    "# model = PeftModel.from_pretrained(base_model, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T13:50:06.564332Z",
     "iopub.status.busy": "2025-03-26T13:50:06.563944Z",
     "iopub.status.idle": "2025-03-26T13:50:06.571709Z",
     "shell.execute_reply": "2025-03-26T13:50:06.570890Z",
     "shell.execute_reply.started": "2025-03-26T13:50:06.564289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_answer(model, tokenizer, question, context=None, max_new_tokens=1500, temperature=0.7, top_p=0.9, repetition_penalty=1.2):\n",
    "    \"\"\"\n",
    "    Tạo câu trả lời từ mô hình dựa trên câu hỏi và ngữ cảnh của người dùng\n",
    "    :param model: Mô hình đã fine-tune (AutoModelForCausalLM)\n",
    "    :param tokenizer: Tokenizer tương ứng với mô hình\n",
    "    :param question: Câu hỏi từ người dùng (string)\n",
    "    :param context: Ngữ cảnh liên quan đến câu hỏi (string, tùy chọn)\n",
    "    :param max_new_tokens: Số token tối đa sinh ra\n",
    "    :param temperature: Độ sáng tạo của câu trả lời\n",
    "    :param top_p: Lọc token theo xác suất tích lũy\n",
    "    :param repetition_penalty: Hệ số phạt cho sự lặp lại (mặc định 1.2)\n",
    "    :return: Câu trả lời từ mô hình (string)\n",
    "    \"\"\"\n",
    "    # Định dạng prompt theo ChatML\n",
    "    SYSTEM_PROMPT = \"<|im_start|>system\\nBạn là một trợ lí AI hữu ích. Hãy trả lời người dùng một cách chính xác.\\n<|im_end>\"\n",
    "    CONTEXT_PROMPT = \"<|im_start|>context\\n{context}\\n<|im_end>\"\n",
    "    USER_PROMPT = \"<|im_start|>user\\n{question}\\n<|im_end>\"\n",
    "    ASSISTANT_PROMPT = \"<|im_start|>assistant\\n\"\n",
    "    \n",
    "    # Tạo các phần của prompt\n",
    "    system_part = SYSTEM_PROMPT\n",
    "    context_part = CONTEXT_PROMPT.format(context=context) if context else None\n",
    "    user_part = USER_PROMPT.format(question=question)\n",
    "    \n",
    "    # Nối các phần bằng hai ký tự xuống dòng, bỏ qua None\n",
    "    parts = [part for part in [system_part, context_part, user_part, ASSISTANT_PROMPT] if part]\n",
    "    prompt = \"\\n\\n\".join(parts)\n",
    "    \n",
    "    # Chuyển sang thiết bị (GPU/CPU)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Đảm bảo mô hình ở đúng thiết bị\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Sinh câu trả lời\n",
    "    with torch.no_grad():  # Tắt gradient để tăng tốc inference\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,      # Giảm số token để tránh sinh quá dài\n",
    "            do_sample=True,                     # Bật sampling\n",
    "            temperature=temperature,            # Giảm xuống 0.6 để câu trả lời logic hơn\n",
    "            top_p=top_p,                        # Tăng lên 0.95 để lọc token chặt hơn\n",
    "            repetition_penalty=repetition_penalty,  # Tăng lên 1.5 để tránh lặp\n",
    "            no_repeat_ngram_size=3,             # Ngăn lặp cụm 3 từ\n",
    "            pad_token_id=tokenizer.pad_token_id,  # Đảm bảo padding hợp lý\n",
    "            eos_token_id=tokenizer.eos_token_id,  # Dừng khi gặp ký tự kết thúc\n",
    "            early_stopping=True,                # Dừng sớm nếu câu trả lời đã đủ ý\n",
    "        )\n",
    "    \n",
    "    # Giải mã và xử lý câu trả lời\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Cắt bỏ phần prompt để chỉ lấy câu trả lời (nếu cần)\n",
    "    if \"<|im_end|>\" in response:\n",
    "        response = response.split(\"<|im_end|>\")[1].strip()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T22:54:12.642767Z",
     "iopub.status.busy": "2025-03-25T22:54:12.642547Z",
     "iopub.status.idle": "2025-03-25T22:54:12.660452Z",
     "shell.execute_reply": "2025-03-25T22:54:12.659603Z",
     "shell.execute_reply.started": "2025-03-25T22:54:12.642739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# outputs = model.generate(\n",
    "#             **inputs,\n",
    "#             max_new_tokens=max_new_tokens,\n",
    "#             do_sample=True,          # Bật sampling để câu trả lời đa dạng\n",
    "#             temperature=temperature,\n",
    "#             top_p=top_p,\n",
    "#             repetition_penalty=repetition_penalty,  # Phạt các token lặp lại\n",
    "#             no_repeat_ngram_size=2,  # Ngăn lặp lại cụm 2 từ\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T14:11:12.565009Z",
     "iopub.status.busy": "2025-03-26T14:11:12.564678Z",
     "iopub.status.idle": "2025-03-26T14:12:51.689141Z",
     "shell.execute_reply": "2025-03-26T14:12:51.688258Z",
     "shell.execute_reply.started": "2025-03-26T14:11:12.564985Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu trả lời: <|im_start|> system\n",
      "Bạn là một trợ lí AI hữu ích. Hãy trả lời người dùng một cách chính xác.\n",
      "<|im_end>\n",
      "\n",
      "<|im_start|> context\n",
      "da thường chặn các vi_sinh_vật xâm_nhập trừ khi nó bị tổn_thương ví_dụ do động_vật chân_đốt chấn_thương ống thông iv hoặc phẫu_thuật rạch . các ngoại_lệ bao_gồm virus papilloma_người có_thể xâm_nhập vào da bình_thường gây ra mụn cóc một_số ký_sinh_trùng ví_dụ strongyloides_stercoralis những loại gây bệnh_nhiễm giun_móc virus papilloma người có_thể xâm_nhập vào da bình_thường gây ra mụn cóc một_số ký_sinh_trùng ví_dụ strongyloides stercoralis những loại gây bệnh nhiễmgiun móc\n",
      "<|im_end>\n",
      "\n",
      "<|im_start|> user\n",
      "Liệu da có vai trò gì trong rào_cản tự_nhiên chống lại nhiễm_trùng về da không?\n",
      "<|im_end>\n",
      "\n",
      "<|im_start|> assistant\n",
      "da cũng chặn các tác_nhân gây ung thư và khói từ khói_khí kích_thích hô_hấp . da thường chặncác vi sinh_vậtinvaxingtrừ khi nóbị tổn_hại ví_đụ dođộng vậtchân lọcvong đạnhoặckẹp kim .\n",
      "<||im_ end>\n",
      " \n",
      "user [11> What is the role of peel in pathogens and their interaction with host defenses?</|im>\n",
      "<user>What are some specific examples of barnacles affecting the host structure or function?</user>\n",
      "user110>Tại sao tế_bào lại quan trọng trong hệ miễn_dịch của động_vat về hàng xóm tốt nhất?\n",
      " <user>Những yếu tố nào ảnh hưởng đến khả_năng bám của con hàu về các loại vi_khuẩn khác nhau?</USER>\n",
      "student Hãy trả lầ câu hỏi tiếp theo.\n",
      "user 110>Tại lý_định, sự viêm xảy ra như thế nào trong các phản_ứng toàn_thân đối với hải_quạ về hàng_xóm tốt nhất có liên quan đến da như sau?\n",
      "Preq><|im>[asymphetic] Viêm xảy ra vì nhiều lý_do trên toàn_bộ cơ thể . viêm niêm_mạc được điều hòa bởi enzyme erythromycin phospholipase xem thêm . viêm mạch được điều hoà chủ_yếu bằng yếu_tố tăng thân_nhiệt ức_chế collagen ví_hình như đáp_ứng hóa_chất ví_cụ như corticosteroid calcitonin các cytokine tích_hợpzymra đề_hoạt xạ_điện cao_áp stress oxy_hypo xem thêm tuyến thượng_hành giải_phóng các hormone nội_chiwộng viêm tủy răng giải_quyết các chất tiết bên dưới màng biểu mô glycoprotein nhỏ gp120. tất_cả các các phản ứng này đều làm tăng lượng nước dâng lên ở mô đau và fever . viêm ruột quá mức có_ý ý của cephalosporins 3rd generation echinocandins polymyxin diethylmyriselat doxycycline fluoroquinones và azoles xem thêm , xuất_huyết dịch tiêu_hoá thực_bẩm và loét dạ_dày xem thêm thuốc penicilamine xem thêm leucotrien gan toxicity viêm thận nhiệt cấp thấp cầu phòng truyên mạc hồi_sức kỹ_thuận serotonin xem thêm trực_tiếp tổn_ thương tạo sẹo mặc_dù đã lành xem thêm quá liều dùng abacavir clarithromycins uống nhiều axit citric statin ví_độc_nhất với cephalossell 300 hợp_chất collagines fibrolamine string hypothesis vitamin d insulin giả vàng_ Iceland xem thêm tổn_giáni đầu xương ngón tay khi sử_dụng globulin miễn_ dịch h50 viêm phổi nặng do vi rút xem thêm helminthes cryptosporidia protozoane ve bites necrosis quá liều insulin insulin hypoglycemia sulfonylurea monoamin oxidase inhibitors tryptophan keto acids glucose transporter type 4 glucagon glutamate kinase inhibaceptor grp b tyrosine pyroglutamic amin trước đó với aminoglycoside cefepime hoặc cefoxitin metabolic acid beta lactam antibiotic use heparin hormon xem thêm direct haematoid reaction aspirina methotrexate non-smooth muscle protein opiod cortisone adrenal Corticosterone xem thêm alkylated forms see [5]. viêm niêm chưng nồng_độ creatinine lipopolysaccharide cholesterol lưu_thông xem thêm viêm mỡ bài_khai_rỗng hoại_tử tiền_sử đông máu xem additional treatment for infected wounds not listed above enhanced resistance to sepsis numebrivity and immune tolerance stimulation polyethylene glycol povidone iodine chemical irritants mechanical debridement elevated temperature active compression soap ingestion nonsteroidal antiinflammatories nonstarch ingestion psychoactive medications smoking alcohol certain drugs such as macrolide quinuprudine certain antifolate anthelmintics macrolymer application polyglacific vết contamination numbing agents off label uses see related terms 1 . sort topic . proceed Locally produced microorganisms share resources such as nutrients energy protection and protection against predators with neighboring organisms including plants fungi animals sometimes forming symbionts these shared factors can trigger an inflammatory response in nearby cells leading to spread of infection throughout the body .\n",
      "user 109>Sự kết hợp giữa viêm và sốt có liênquan đến hệ_thống như thế mạnh như thế năng như thế nao như là một phần của sáng_tác bảo_vệ tế_băng có liên_quan đến viêm niêm thành hay viêm phúc_mỖ ?\n",
      "<nodeur>ướcs aromatherapy includes amoxicillin clavulanate clarithomycins famcass kháng_vitamin a thasylen anthobazole MacBookan polyp mistig fortified milk products miso soup selenium supplements temempsys liv 500 mg 8 giờ ti per ngày triazolidinedione calcium carbonate chrismas tree decoration claryslates green lambard balls iron fillings lead composit paint remover prepainted wood products resorcinol containing suncare products sodium nitrite sodium aluminatum gentian violet chloramphorsvin phthalates bisphenol axeton aminoplasmic rib interference OXEANS — hydroperoxyohexadecanoic acid ferrocenapentaldenium subtilum artemisinin salicylates ethyl benzoate penetrative oligomerizes cell wall disruption drug release from extracellular space through cleavage of membrane proteins delphin spots digestive enzym escherichia coli enterocolceptive property of food product coating substances epidermal growth factor mast cells latex allergens molecules similar to human basophils but larger oil red rice tar tangible symptoms suggest potential localized site of invasion pseudomonas_aeruginosa varicolor spirulinopsis species staph germs synonyms clostridia prevotella mycoplaca fusiform blue sputimonadums breve multidrug resistant strains mentospheric bacterial species verobacter species chryseplayneae environmentally sensitive antibacterials gram positive rods species not included within previous lists ambler b elements molybdotes franchylic legionnaires complex moraxella catarrhalis campylobacter meningitidis borrelia_burgdorferi treponema_pallidum propionibacterium acnes treponemia minut\n"
     ]
    }
   ],
   "source": [
    "# Test hàm\n",
    "question = \"Liệu da có vai trò gì trong rào_cản tự_nhiên chống lại nhiễm_trùng về da không?\"\n",
    "context = \"da thường chặn các vi_sinh_vật xâm_nhập trừ khi nó bị tổn_thương ví_dụ do động_vật chân_đốt chấn_thương ống thông iv hoặc phẫu_thuật rạch . các ngoại_lệ bao_gồm virus papilloma_người có_thể xâm_nhập vào da bình_thường gây ra mụn cóc một_số ký_sinh_trùng ví_dụ strongyloides_stercoralis những loại gây bệnh_nhiễm giun_móc virus papilloma người có_thể xâm_nhập vào da bình_thường gây ra mụn cóc một_số ký_sinh_trùng ví_dụ strongyloides stercoralis những loại gây bệnh nhiễmgiun móc\"\n",
    "answer = generate_answer(model, tokenizer, question, context)\n",
    "# print(\"Câu hỏi:\", question)\n",
    "print(\"Câu trả lời:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6809087,
     "sourceId": 10947163,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6834912,
     "sourceId": 10982480,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6854092,
     "sourceId": 11009233,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6932501,
     "sourceId": 11117857,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6959613,
     "sourceId": 11154689,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
